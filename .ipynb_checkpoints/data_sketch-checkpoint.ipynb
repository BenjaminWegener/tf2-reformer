{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<mediawiki xmlns=\"http://www.mediawiki.org/xml/export-0.3/\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.mediawiki.org/xml/export-0.3/ http://www.mediawiki.org/xml/export-0.3.xsd\" version=\"0.3\" xml:lang=\"en\">\\n  <siteinfo>\\n    <sitename>Wikipedia</sitename>\\n    <base>http://en.wikipedia.org/wiki/Main_Page</base>\\n    <generator>MediaWiki 1.6alpha</generator>\\n    <case>first-letter</case>\\n      <namespaces>\\n      <namespace key=\"-2\">Media</namespace>\\n      <namespace key=\"-1\">Special</namespace>\\n      <namespace key=\"0\" />\\n      <namespace key=\"1\">Talk</namespace>\\n      <namespace key=\"2\">User</namespace>\\n      <namespace key=\"3\">User talk</namespace>\\n      <namespace key=\"4\">Wikipedia</namespace>\\n      <namespace key=\"5\">Wikipedia talk</namespace>\\n      <namespace key=\"6\">Image</namespace>\\n      <namespace key=\"7\">Image talk</namespace>\\n      <namespace key=\"8\">MediaWiki</namespace>\\n      <namespace key=\"9\">MediaWiki talk</namespace>\\n      <namespace key=\"10\">Template</namespace>\\n      <namespace key=\"11\">Template talk</namespace>\\n      <namespace key=\"12\">Help</namespace>\\n      <namespace key=\"13\">Help talk</namespace>\\n      <namespace key=\"14\">Category</namespace>\\n      <namespace key=\"15\">Category talk</namespace>\\n      <namespace key=\"100\">Portal</namespace>\\n      <namespace key=\"101\">Portal talk</namespace>\\n    </namespaces>\\n  </siteinfo>\\n  <page>\\n    <title>AaA</title>\\n    <id>1</id>\\n    <revision>\\n      <id>32899315</id>\\n      <timestamp>2005-12-27T18:46:47Z</timestamp>\\n      <contributor>\\n        <username>Jsmethers</username>\\n        <id>614213</id>\\n      </contributor>\\n      <text xml:space=\"preserve\">#REDIRECT [[AAA]]</text>\\n    </revision>\\n  </page>\\n  <page>\\n    <title>AlgeriA</title>\\n    <id>5</id>\\n    <revision>\\n      <id>18063769</id>\\n      <timestamp>2005-07-03T11:13:13Z</timestamp>\\n      <contributor>\\n        <username>Docu</username>\\n        <id>8029</id>\\n      </contributor>\\n      <minor />\\n      <comment>adding cur_id=5: {{R from CamelCase}}</comment>\\n      <text xml:space=\"preserve\">#REDIRECT [[Algeria]]{{R from CamelCase}}</text>\\n    </revision>\\n  </page>\\n  <page>\\n    <title>AmericanSamoa</title>\\n    <id>6</id>\\n    <revision>\\n      <id>18063795</id>\\n      <timestamp>2005-07-03T11:14:17Z</timestamp>\\n      <contributor>\\n        <username>Docu</username>\\n        <id>8029</id>\\n      </contributor>\\n      <minor />\\n      <comment>adding to cur_id=6  {{R from CamelCase}}</comment>\\n      <text xml:space=\"preserve\">#REDIRECT [[American Samoa]]{{R from CamelCase}}</text>\\n    </revision>\\n  </page>\\n  <page>\\n    <title>AppliedEthics</title>\\n    <id>8</id>\\n    <revision>\\n      <id>15898943</id>\\n      <timestamp>2002-02-25T15:43:11Z</timestamp>\\n      <contributor>\\n        <ip>Conversion script</ip>\\n      </contributor>\\n      <minor />\\n      <comment>Automated conversion</comment>\\n      <text xml:space=\"preserve\">#REDIRECT [[Applied ethics]]\\n</text>\\n    </revision>\\n  </page>\\n  <page>\\n    <title>AccessibleComputing</title>\\n    <id>10</id>\\n    <revision>\\n      <id>15898945</id>\\n      <timestamp>2003-04-25T22:18:38Z</timestamp>\\n      <contributor>\\n        <username>Ams80</username>\\n        <id>7543</id>\\n      </contributor>\\n      <minor />\\n      <comment>Fixing redirect</comment>\\n      <text xml:space=\"preserve\">#REDIRECT [[Accessible_computing]]</text>\\n    </revision>\\n  </page>\\n  <page>\\n    <title>AdA</title>\\n    <id>11</id>\\n    <revision>\\n      <id>15898946</id>\\n      <timestamp>2002-09-22T16:02:58Z</timestamp>\\n      <contributor>\\n        <username>Andre Engels</username>\\n        <id>300</id>\\n      </contributor>\\n      <minor />\\n      <text xml:space=\"preserve\">#REDIRECT [[Ada programming language]]</text>\\n    </revision>\\n  </page>\\n  <page>\\n    <title>Anarchism</title>\\n    <id>12</id>\\n    <revision>\\n      <id>42136831</id>\\n      <timestamp>2006-03-04T01:41:25Z</timestamp>\\n      <contributor>\\n        <username>CJames745</username>\\n        <id>832382</id>\\n      </contributor>\\n      <minor />\\n      <comment>/* Anarchist Communism */  too many brackets</comment>\\n      <text xml:space=\"preserve\">{{Anarchism}}\\n\\'\\'\\'Anarchism\\'\\'\\' originated as a term of abuse first used against early [[working class]] [[radical]]s including the [[Diggers]] of the [[English Revolution]] and the [[sans-culotte|\\'\\'sans-culottes\\'\\']] of the [[French Revolution]].[http://uk.encarta.msn.com/encyclopedia_761568770/Anarchism.html] Whilst the term is still used in a pejorative way to describe \\'\\'&quot;any act that used violent means to destroy the organization of society&quot;\\'\\'&lt;ref&gt;[http://www.cas.sc.edu/socy/faculty/deflem/zhistorintpolency.html History of International Police Cooperation], from the final protocols of the &quot;International Conference of Rome for the Social Defense Against Anarchists&quot;, 1898&lt;/ref&gt;, it has also been taken up as a positive label by self-defined anarchists.\\n\\nThe word \\'\\'\\'anarchism\\'\\'\\' is [[etymology|derived from]] the [[Greek language|Greek]] \\'\\'[[Wiktionary:&amp;#945;&amp;#957;&amp;#945;&amp;#961;&amp;#967;&amp;#943;&amp;#945;|&amp;#945;&amp;#957;&amp;#945;&amp;#961;&amp;#967;&amp;#943;&amp;#945;]]\\'\\' (&quot;without [[archon]]s (ruler, chief, king)&quot;). Anarchism as a [[political philosophy]], is the belief that \\'\\'rulers\\'\\' are unnecessary and should be abolished, although there are differing interpretations of what this means. Anarchism also refers to related [[social movement]]s) that advocate the elimination of authoritarian institutions, particularly the [[state]].&lt;ref&gt;[http://en.wikiquote.org/wiki/Definitions_of_anarchism Definitions of anarchism] on Wikiquote, accessed 2006&lt;/ref&gt; The word &quot;[[anarchy]],&quot; as most anarchists use it, does not imply [[chaos]], [[nihilism]], or [[anomie]], but rather a harmonious [[anti-authoritarian]] society. In place of what are regarded as authoritarian political structures and coercive economic institutions, anarchists advocate social relations based upon [[voluntary association]] of autonomous individuals, [[mutual aid]], and [[self-governance]]. \\n    \\nWhile anarchism is most easily defined by what it is against, anarchists also offer positive visions of what they believe to be a truly free society. However, ideas about how an anarchist society might work vary considerably, especially with respect to economics; there is also disagreement about how a free society might be brought about. \\n\\n== Origins and predecessors ==\\n\\n[[Peter Kropotkin|Kropotkin]], and others, argue that before recorded [[history]], human society was organized on anarchist principles.&lt;ref&gt;[[Peter Kropotkin|Kropotkin]], Peter. \\'\\'&quot;[[Mutual Aid: A Factor of Evolution]]&quot;\\'\\', 1902.&lt;/ref&gt; Most anthropologists follow Kropotkin and Engels in believing that hunter-gatherer bands were egalitarian and lacked division of labour, accumulated wealth, or decreed law, and had equal access to resources.&lt;ref&gt;[[Friedrich Engels|Engels]], Freidrich. \\'\\'&quot;[http://www.marxists.org/archive/marx/works/1884/origin-family/index.htm Origins of the Family, Private Property, and the State]&quot;\\'\\', 1884.&lt;/ref&gt;\\n[[Image:WilliamGodwin.jpg|thumb|right|150px|William Godwin]]\\n\\nAnarchists including the [[The Anarchy Organisation]] and [[Murray Rothbard|Rothbard]] find anarchist attitudes in [[Taoism]] from [[History of China|Ancient China]].&lt;ref&gt;The Anarchy Organization (Toronto). \\'\\'Taoism and Anarchy.\\'\\' [[April 14]] [[2002]] [http://www.toxicpop.co.uk/library/taoism.htm Toxicpop mirror] [http://www.geocities.com/SoHo/5705/taoan.html Vanity site mirror]&lt;/ref&gt;&lt;ref&gt;[[Murray Rothbard|Rothbard]], Murray. \\'\\'&quot;[http://www.lewrockwell.com/rothbard/ancient-chinese.html The Ancient Chinese Libertarian Tradition]&quot;\\'\\', an extract from \\'\\'&quot;[http://www.mises.org/journals/jls/9_2/9_2_3.pdf Concepts of the Role of Intellectuals in Social Change Toward Laissez Faire]&quot;\\'\\', The Journal of Libertarian Studies, 9 (2) Fall 1990.&lt;/ref&gt; [[Peter Kropotkin|Kropotkin]] found similar ideas in [[stoicism|stoic]] [[Zeno of Citium]]. According to Kropotkin, Zeno &quot;repudiated the omnipotence of the state, its intervention and regimentation, and proclaimed the sovereignty of the moral law of the individual&quot;. &lt;ref&gt;[http://www.blackcrayon.com/page.jsp/library/britt1910.html Anarchism], written by Peter Kropotkin, from Encyclopaedia Britannica, 1910]&lt;/ref&gt;\\n\\nThe [[Anabaptist]]s of 16th century Europe are sometimes considered to be religious forerunners of modern anarchism. [[Bertrand Russell]], in his \\'\\'History of Western Philosophy\\'\\', writes that the Anabaptists &quot;repudiated all law, since they held that the good man will be guided at every moment by [[the Holy Spirit]]...[f]rom this premise they arrive at [[communism]]....&quot;&lt;ref&gt;[[Bertrand Russell|Russell]], Bertrand. \\'\\'&quot;Ancient philosophy&quot;\\'\\' in \\'\\'A History of Western Philosophy, and its connection with political and social circumstances from the earliest times to the present day\\'\\', 1945.&lt;/ref&gt; [[Diggers (True Levellers)|The Diggers]] or &quot;True Levellers&quot; were an early communistic movement during the time of the [[English Civil War]], and are considered by some as forerunners of modern anarchism.&lt;ref&gt;[http://www.zpub.com/notes/aan-hist.html An Anarchist Timeline], from Encyclopaedia Britannica, 1994.&lt;/ref&gt;\\n\\nIn the [[modern era]], the first to use the term to mean something other than chaos was [[Louis-Armand de Lom d\\'Arce de Lahontan, Baron de Lahontan|Louis-Armand, Baron de Lahontan]] in his \\'\\'Nouveaux voyages dans l\\'Am\\xc3\\xa9rique septentrionale\\'\\', (1703), where he described the [[Native Americans in the United States|indigenous American]] society, which had no state, laws, prisons, priests, or private property, as being in anarchy&lt;ref&gt;[http://etext.lib.virginia.edu/cgi-local/DHI/dhi.cgi?id=dv1-12 Dictionary of the History of Ideas - ANARCHISM]&lt;/ref&gt;. [[Russell Means]], a [[libertarian]] and l'\n",
      "<mediawiki\n",
      "[ 60 109 101 100 105  97 119 105 107 105  32 120 109 108 110 115  61  34\n",
      " 104 116 116 112  58  47  47 119 119 119  46 109 101 100 105  97 119 105\n",
      " 107 105  46 111 114 103  47 120 109 108  47 101 120 112 111 114 116  45\n",
      "  48  46  51  47  34  32 120 109 108 110 115  58 120 115 105  61  34 104\n",
      " 116 116 112  58  47  47 119 119 119  46 119  51  46 111 114 103  47  50\n",
      "  48  48  49  47  88  77  76  83  99 104]\n",
      "(95000000,)\n",
      "5000000\n",
      "tensor([101, 114, 110,  ...,  47,  47, 119], dtype=torch.uint8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import gzip\n",
    "import torch\n",
    "with gzip.open('../reformer-pytorch/examples/enwik8_simple/data/enwik8.gz') as file:\n",
    "    readed=file.read(int(95e6))\n",
    "    print(readed[:10000])\n",
    "    X = np.fromstring(readed, dtype=np.uint8)\n",
    "    print((readed[:10000].split()[0]).decode(\"utf-8\") )\n",
    "    print(X[:100])\n",
    "    print(X.shape)\n",
    "    trX, vaX = np.split(X, [int(90e6)])\n",
    "    print(len(vaX))\n",
    "    data_train, data_val = torch.from_numpy(trX), torch.from_numpy(vaX)\n",
    "    print(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 97  98  99  32  99 100 101]\n"
     ]
    }
   ],
   "source": [
    "print(np.frombuffer(b'abc cde',dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_byte_pair_encoding(vocab_size):\n",
    "\tprint(\"Training BytePair encoding......\")\n",
    "\ttoken_dict = Counter()\n",
    "\twith open(PROCESS_DATA_PATH, 'r') as fr:\n",
    "\t\tfor line in tqdm.tqdm(fr):\n",
    "\t\t\ttoken_dict.update(line.lower().split())\n",
    "\n",
    "\twith open(BPE_TSV_PATH, 'w', newline='') as f_output:\n",
    "\t\ttsv_output = csv.writer(f_output, delimiter='\\t')\n",
    "\t\tfor word in token_dict:\n",
    "\t\t\ttsv_output.writerow([word, token_dict[word]])\n",
    "\n",
    "\tspmcmd = '--input={spm_input} --model_prefix={spm_model} --input_format=tsv --vocab_size={vocab_size} --user_defined_symbols=[SEP],[BOS],[EOS] --hard_vocab_limit=false --model_type=bpe --pad_id=0 --unk_id=1 --bos_id=-1 --eos_id=-1 --pad_piece=[PAD] --unk_piece=[UNK]'.format(\n",
    "\t\tspm_input=BPE_TSV_PATH, spm_model=BPE_MODEL_PATH, vocab_size=vocab_size)\n",
    "\tspm.SentencePieceTrainer.train(spmcmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_byte_pair_encoding(vocab_size):\n",
    "\tprint(\"Training BytePair encoding......\")\n",
    "\ttoken_dict = Counter()\n",
    "\twith open(PROCESS_DATA_PATH, 'r') as fr:\n",
    "\t\tfor line in tqdm.tqdm(fr):\n",
    "\t\t\ttoken_dict.update(line.lower().split())\n",
    "\n",
    "\twith open(BPE_TSV_PATH, 'w', newline='') as f_output:\n",
    "\t\ttsv_output = csv.writer(f_output, delimiter='\\t')\n",
    "\t\tfor word in token_dict:\n",
    "\t\t\ttsv_output.writerow([word, token_dict[word]])\n",
    "\n",
    "\tspmcmd = '--input={spm_input} --model_prefix={spm_model} --input_format=tsv --vocab_size={vocab_size} --user_defined_symbols=[SEP],[BOS],[EOS] --hard_vocab_limit=false --model_type=bpe --pad_id=0 --unk_id=1 --bos_id=-1 --eos_id=-1 --pad_piece=[PAD] --unk_piece=[UNK]'.format(\n",
    "\t\tspm_input=BPE_TSV_PATH, spm_model=BPE_MODEL_PATH, vocab_size=vocab_size)\n",
    "\tspm.SentencePieceTrainer.train(spmcmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TextSamplerDataset():\n",
    "    def __init__(self, data, seq_len):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        rand_start = np.random.randint(0,len(self.data) - self.seq_len - 1, (1,))[0]\n",
    "        print(rand_start)\n",
    "        full_seq = self.data[rand_start: rand_start + self.seq_len + 1]\n",
    "        return full_seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) // self.seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_fn(dataset):\n",
    "    for i in range(len(dataset)):\n",
    "        yield dataset[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = tf.data.Dataset.from_generator(functools.partial(\n",
    "    \tgenerator_fn, sampler_dat), output_types=(tf.int64, tf.int64, tf.int64, tf.int64), output_shapes=([seq_length],[seq_length],[seq_length],[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1305260\n",
      "50197\n",
      "finish token_dict\n",
      "finish write bpe tsv\n",
      "finish train bpe \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "from collections import Counter\n",
    "import csv\n",
    "import sentencepiece as spm\n",
    "import os \n",
    "\n",
    "#_ROOT = os.path.abspath(os.path.dirname(__file__))\n",
    "\n",
    "BPE_TSV_PATH =\"bpe_spm.tsv\"\n",
    "BPE_MODEL_PATH = \"bpe_model\"\n",
    "\n",
    "BOS_ID = 3\n",
    "EOS_ID = 4\n",
    "trsh = 5\n",
    "vocab_size = 30000\n",
    "\n",
    "token_dict = Counter()\n",
    "with gzip.open('../reformer-pytorch/examples/enwik8_simple/data/enwik8.gz') as file:\n",
    "    readed=file.read(int(95e6)).decode(\"utf-8\") \n",
    "    dataset = readed.lower().split()\n",
    "    \n",
    "    token_dict.update(dataset)\n",
    "    \n",
    "    \n",
    "    trsh = 15\n",
    "    print(len(token_dict))\n",
    "    token_dict = Counter(dict(filter(lambda x: x[1] >= trsh, token_dict.items())))\n",
    "    print(len(token_dict))\n",
    "\n",
    "\n",
    "\n",
    "    print(\"finish token_dict\")\n",
    "    #write vocab as tsv\n",
    "    with open(BPE_TSV_PATH, 'w', newline='') as f_output:\n",
    "        tsv_output = csv.writer(f_output, delimiter='\\t')\n",
    "        for word in token_dict:\n",
    "            tsv_output.writerow([word, token_dict[word]])\n",
    "    print(\"finish write bpe tsv\")\n",
    "    spmcmd = '--input={spm_input} --model_prefix={spm_model} --input_format=tsv --vocab_size={vocab_size} --user_defined_symbols=[SEP],[BOS],[EOS] --hard_vocab_limit=false --model_type=bpe --pad_id=0 --unk_id=1 --bos_id=-1 --eos_id=-1 --pad_piece=[PAD] --unk_piece=[UNK]'.format(\n",
    "        spm_input=BPE_TSV_PATH, spm_model=BPE_MODEL_PATH, vocab_size=vocab_size)\n",
    "    spm.SentencePieceTrainer.train(spmcmd)\n",
    "    print(\"finish train bpe \")\n",
    "    \"\"\"\n",
    "    print(\"go\")\n",
    "    sampler_dataset = TextSamplerDataset(dataset,100)\n",
    "    \n",
    "    generator = generator_fn(sampler_dataset)\n",
    "    for x in generator:\n",
    "        print(x)\n",
    "        break\n",
    "    d = tf.data.Dataset.from_generator(functools.partial(\n",
    "    generator_fn, sampler_dataset), output_types=(tf.int64, tf.int6), output_shapes=([seq_length],[seq_length]))\n",
    "    \n",
    "    \"\"\"\n",
    "    #token_dict.update(readed.lower().split())\n",
    "    #print(len(token_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23113, 1213, 630, 57, 1139, 15204, 5814]\n"
     ]
    }
   ],
   "source": [
    "s = spm.SentencePieceProcessor()\n",
    "s.Load(BPE_MODEL_PATH + \".model\")\n",
    "print(s.encode_as_ids(\"hello my name is domyoung lee\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_fn(dataset,tokenizer, bs,seq_len ):\n",
    "    for i in range(len(dataset)):\n",
    "        line = dataset[i]\n",
    "        encoded_id = tokenizer.encode_as_ids(line)\n",
    "        if len(encoded_id) < seq_len-1:\n",
    "            encoded_id = encoded_id + [0]*((seq_len-1)-len(encoded))\n",
    "        if len(encoded_id) > seq_len-1:\n",
    "            encoded_id = encoded_id[:seq_len-1]\n",
    "        inputs = np.array([BOS_ID] + encoded_id)\n",
    "        targets = np.array( encoded_id[:,1:])\n",
    "        yield inputs,targets\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = generator_fn(sampler_dataset,s,10,100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7035655\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'method' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-69a6917ee806>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-95-d37adcd8ead1>\u001b[0m in \u001b[0;36mgenerator_fn\u001b[0;34m(dataset, tokenizer, bs, seq_len)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mencoded_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_as_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mencoded_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'method' has no len()"
     ]
    }
   ],
   "source": [
    "for x in generator:\n",
    "    print(x)\n",
    "    print(x[0].shape,x[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
